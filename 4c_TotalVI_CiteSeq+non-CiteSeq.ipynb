{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import matplotlib\n",
    "matplotlib.rcParams[\"pdf.fonttype\"] = 42\n",
    "matplotlib.rcParams[\"ps.fonttype\"] = 42\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as random\n",
    "import pandas as pd\n",
    "import scanpy as sc\n",
    "import louvain\n",
    "import torch\n",
    "\n",
    "from scvi.dataset import Dataset10X, CsvDataset, AnnDatasetFromAnnData, CellMeasurement, LoomDataset, DownloadableAnnDataset\n",
    "from scvi.dataset.dataset import GeneExpressionDataset\n",
    "from scvi.inference import TotalPosterior, TotalTrainer, load_posterior\n",
    "from scvi.models import SCANVI, TOTALVI\n",
    "from scvi import set_seed\n",
    "\n",
    "from umap import UMAP\n",
    "\n",
    "# Control UMAP numba warnings\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "set_seed(123)\n",
    "\n",
    "use_cuda = True\n",
    "show_plot = True\n",
    "test_mode = False\n",
    "sampleFolder = \"/PATH/TO/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### See script 4b_TotalVI.ipynb (idem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Concatenate datasets - via union\n",
    "all_dataset = GeneExpressionDataset()\n",
    "all_dataset.populate_from_datasets([dataset1, dataset2, dataset3], \n",
    "                                    cell_measurement_intersection={\"protein_expression\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check out merged dataset\n",
    "all_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save before taking HVG\n",
    "import pickle\n",
    "pickle.dump(all_dataset, open(\"/PATH/TO/all_dataset.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get HVGenes\n",
    "all_dataset.subsample_genes(4000, batch_correction = True, mode = \"seurat_v2\")\n",
    "all_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataset.protein_expression.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataset.gene_names[0:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataset.protein_names[0:19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataset.batch_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sample1 = non-CiteSeq = batch index 0\n",
    "## Sample2 = CiteSeq = batch index 1\n",
    "## Sample3 = CiteSeq = batch index 2\n",
    "\n",
    "\n",
    "### Remove the ABs counts of non-CiteSeq samples (replace by zero's) --> Dummie count table made in Rscript\n",
    "all_dataset.protein_expression[all_dataset.batch_indices.ravel() == 0] = np.zeros_like(\n",
    "    all_dataset.protein_expression[all_dataset.batch_indices.ravel() == 0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_mask = all_dataset.get_batch_mask_cell_measurement(\"protein_expression\")\n",
    "batch_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataset.protein_names[np.logical_not(batch_mask[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch_mask[1].shape)\n",
    "print(batch_mask[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataset.n_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save merged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save\n",
    "import pickle\n",
    "pickle.dump(all_dataset, open(\"PATH/TO/HVG_dataset.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload merged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load data again\n",
    "import pickle\n",
    "all_dataset = pickle.load(open(\"/PATH/TO/HVG_dataset.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load full dataset again\n",
    "import pickle\n",
    "all_dataset_full = pickle.load(open(\"/PATH/TO/results_TotalVI/all_dataset.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataset_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initialize trainer\n",
    "use_cuda = True\n",
    "lr = 0.001\n",
    "n_epochs = 400\n",
    "\n",
    "# early_stopping_kwargs = {\n",
    "#     \"early_stopping_metric\": \"elbo\",\n",
    "#     \"save_best_state_metric\": \"elbo\",\n",
    "#     \"patience\": 45,\n",
    "#     \"threshold\": 0,\n",
    "#     \"reduce_lr_on_plateau\": True,\n",
    "#     \"lr_patience\": 30,\n",
    "#     \"lr_factor\": 0.6,\n",
    "#     \"posterior_class\": TotalPosterior,\n",
    "# }\n",
    "\n",
    "\n",
    "totalvae=TOTALVI(all_dataset.nb_genes, len(all_dataset.protein_names), \n",
    "                 n_batch=all_dataset.n_batches, n_latent=20, \n",
    "                 encoder_batch=True, protein_batch_mask=batch_mask)\n",
    "\n",
    "### Prepare trainer\n",
    "trainer = TotalTrainer(\n",
    "    totalvae,\n",
    "    all_dataset,\n",
    "    train_size=0.90,\n",
    "    test_size=0.10,\n",
    "    use_cuda=use_cuda,\n",
    "    frequency=1,\n",
    "    batch_size=256,\n",
    "    early_stopping_kwargs=None,\n",
    "    use_adversarial_loss=True if all_dataset.n_batches > 1 else False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Do training\n",
    "print(\"Start =\", datetime.now().strftime(\"%H:%M:%S\"))\n",
    "\n",
    "trainer.train(lr=lr, n_epochs=n_epochs)\n",
    "\n",
    "print(\"End =\", datetime.now().strftime(\"%H:%M:%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plotting likelihood\n",
    "plt.plot(trainer.history[\"elbo_train_set\"], label=\"train\")\n",
    "plt.plot(trainer.history[\"elbo_test_set\"], label=\"test\")\n",
    "plt.title(\"Negative ELBO over training epochs\")\n",
    "plt.ylim(1000,1500)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get full posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get full posterior\n",
    "full_posterior = trainer.create_posterior(\n",
    "    totalvae, all_dataset, indices=np.arange(len(all_dataset)), type_class=TotalPosterior\n",
    ")\n",
    "full_posterior = full_posterior.update({\"batch_size\":32})\n",
    "\n",
    "### Extract latent space\n",
    "latent, batch_indices, label, library_gene = full_posterior.sequential().get_latent()\n",
    "batch_indices = batch_indices.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())\n",
    "print(sampleFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save\n",
    "import pickle\n",
    "pickle.dump(full_posterior, open(\"/PATH/TO/fullPosterior.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load data again\n",
    "import pickle\n",
    "full_posterior = pickle.load(open(\"/PATH/TO/fullPosterior.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent, batch_indices, label, library_gene = full_posterior.sequential().get_latent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create adata object\n",
    "post_adata = sc.AnnData(X=all_dataset.X)\n",
    "post_adata.var.index = all_dataset.gene_names\n",
    "post_adata.obsm[\"X_totalVI\"] = latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_adata.obsm[\"X_totalVI\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### table() of batch indices\n",
    "print(np.array(np.unique(all_dataset.batch_indices, return_counts=True)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run umap\n",
    "#The higher the min_dist, the closer the clusters\n",
    "sc.pp.neighbors(post_adata, use_rep=\"X_totalVI\", n_neighbors=30, metric=\"correlation\")\n",
    "sc.tl.umap(post_adata, min_dist=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Run clustering\n",
    "sc.tl.louvain(post_adata, key_added=\"louvain\", resolution=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Prepare for umap\n",
    "d_names = [\"Sample1\",\"Sample2\",\"Sample3\"]\n",
    "post_adata.obs[\"sample\"] = [d_names[int(b)] for b in all_dataset.batch_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_adata.obs[\"type\"] = \"RnaSeq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sampleName in [\"Sample2\",\"Sample3\"]:\n",
    "#     print (sampleName)\n",
    "    post_adata.obs.loc[post_adata.obs['sample']==sampleName, 'type']='Citeseq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_adata.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(np.unique(post_adata.obs['type'], return_counts=True)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds = np.random.permutation(np.arange(all_dataset.X.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_dataset.X.shape)\n",
    "print(inds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create umap\n",
    "figUmap = sc.pl.umap(\n",
    "    post_adata, \n",
    "    color=\"louvain\",\n",
    "    ncols=1,\n",
    "    alpha=0.9,\n",
    "    legend_loc=\"on data\",\n",
    "#     legend_loc=\"right margin\",\n",
    "    return_fig=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create umap split on sample\n",
    "figUmapSplitSample = sc.pl.umap(\n",
    "    post_adata[inds], \n",
    "    color=[\"sample\"],\n",
    "    ncols=1,\n",
    "    alpha=0.9,\n",
    "    return_fig=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create umap split on type\n",
    "figUmapSplitType = sc.pl.umap(\n",
    "    post_adata[inds], \n",
    "    color=[\"type\"],\n",
    "    ncols=1,\n",
    "    alpha=0.9,\n",
    "    return_fig=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save plots\n",
    "figUmap.savefig(\"PATH/TO/umap.png\", dpi=200, bbox_inches='tight')\n",
    "figUmapSplitSample.savefig(\"PATH/TO/results_TotalVI/umapSplitSample.png\", dpi=200, bbox_inches='tight')\n",
    "figUmapSplitType.savefig(\"PATH/TO/results_TotalVI/umapSplitType.png\", dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get denoised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Monte Carlo samples to average over\n",
    "n_samples = 10\n",
    "parsed_protein_names=all_dataset.protein_names.tolist()\n",
    "\n",
    "# Probability of background for each (cell, protein)\n",
    "py_mixing = full_posterior.sequential().get_sample_mixing(n_samples=n_samples, give_mean=True)\n",
    "protein_foreground_prob = pd.DataFrame(\n",
    "    data=(1 - py_mixing), columns=parsed_protein_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Denoised genes for all samples\n",
    "denoised_genes_reallyAll, denoised_proteins_reallyAll = full_posterior.sequential().get_normalized_denoised_expression(\n",
    "    n_samples=n_samples, give_mean=True\n",
    ")\n",
    "print(denoised_genes_reallyAll.shape)\n",
    "print(denoised_proteins_reallyAll.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Denoised genes for all citeSeq samples\n",
    "denoised_genes_all, denoised_proteins_all = full_posterior.sequential().get_normalized_denoised_expression(\n",
    "    n_samples=n_samples, give_mean=True, transform_batch=[1,2] ## sample batch index\n",
    ")\n",
    "print(denoised_genes_all.shape)\n",
    "print(denoised_proteins_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Denoised genes for sample3 because it has a different amount of ABs (20 more) added than sample2\n",
    "denoised_genes_Sample3, denoised_proteins_Sample3 = full_posterior.sequential().get_normalized_denoised_expression(\n",
    "    n_samples=n_samples, give_mean=True, transform_batch=[2] ## sample batch index\n",
    ")\n",
    "print(denoised_genes_Sample3.shape)\n",
    "print(denoised_proteins_Sample3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load txt files containing overlap and sample3 ABs created in the 4a_pre_TotalVI-ScVI.R script\n",
    "fileName=\"PATH/TO/overlapABs.txt\"\n",
    "overlapABs = np.loadtxt(fileName, dtype='str')\n",
    "\n",
    "fileName=\"PATH/TO/ABs_Sample3.txt\"\n",
    "ABs_Sample3 = np.loadtxt(fileName, dtype='str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlapABs_IDs=[]\n",
    "for i in range(len(overlapABs)):\n",
    "    theIndex=parsed_protein_names.index(overlapABs[i])\n",
    "    overlapABs_IDs.append(theIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABs_Sample3_IDs=[]\n",
    "for i in range(len(ABs_Sample3)):\n",
    "    theIndex=parsed_protein_names.index(ABs_Sample3[i])\n",
    "    ABs_Sample3_IDs.append(theIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised_proteins_overlap=denoised_proteins_all[:,overlapABs_IDs]\n",
    "denoised_proteins_Sample3=denoised_proteins_Sample3[:,ABs_Sample3_IDs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(denoised_proteins_overlap.shape)\n",
    "print(denoised_proteins_Sample3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised_genes=denoised_genes_reallyAll\n",
    "denoised_proteins=np.concatenate((denoised_proteins_overlap,\n",
    "                                  denoised_proteins_Sample3), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(denoised_genes.shape)\n",
    "print(denoised_proteins.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(parsed_protein_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_protein_names_New=np.concatenate((overlapABs, Sample3)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(parsed_protein_names_New)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get raw values\n",
    "combined_protein = all_dataset.protein_expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_protein.shape)\n",
    "print(protein_foreground_prob.shape)\n",
    "print(denoised_proteins.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add normalised protein values to post_adata (via obs)\n",
    "for i, p in enumerate(parsed_protein_names):\n",
    "    post_adata.obs[\"{}_fore_prob\".format(p)] = protein_foreground_prob[p].values\n",
    "    post_adata.obs[\"{}_observed\".format(p)] = combined_protein[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add normalised protein values to post_adata (via obs)\n",
    "for i, p in enumerate(parsed_protein_names_New):\n",
    "    post_adata.obs[\"{}\".format(p)] = denoised_proteins[:, i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Add normalised gene values to post_adata (via layer)\n",
    "post_adata.layers[\"norm_genes\"] = denoised_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_adata.var.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Save post_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_adata.obs[\"sample\"] = post_adata.obs[\"sample\"].astype(\"str\")\n",
    "post_adata.obs[\"louvain\"] = post_adata.obs[\"louvain\"].astype(\"int\")\n",
    "post_adata.obs[\"type\"] = post_adata.obs[\"type\"].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Save\n",
    "import pickle\n",
    "pickle.dump(post_adata, open(\"PATH/TO/post_adata.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Reload post_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The next steps are the same as in script 4b_TotalVI.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
